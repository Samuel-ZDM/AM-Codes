{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**<h1>Exemplo: Curvas de Aprendizado (Learning Curves) + Métricas de Avaliação</h1>**\n",
        "<h2>Classificador de formas geométricas com três classes: \"círculos\", \"quadrados\" e \"triângulos\"</h2>\n",
        "<h4>Exemplo contém uso de callbacks de treino (modelcheckpoint, earlystopping)</h4>\n",
        "<hr>\n",
        "<h3>Prof. Dr. Rafael Rieder</h3>\n",
        "<h5>Universidade de Passo Fundo. Última atualização: 10/10/2023</h5>"
      ],
      "metadata": {
        "id": "cfGxfmThpq2z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importação das dependências"
      ],
      "metadata": {
        "id": "UOuybAc1euuG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yVeGSudeA7V"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "import numpy as np\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras import backend as K\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import load_img, img_to_array\n",
        "from keras.regularizers import l2\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from itertools import cycle\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "# from keras.models import load_model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Montagem do Drive e definição dos caminhos"
      ],
      "metadata": {
        "id": "NXTL0pivetvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CURRDIR = os.path.dirname(__file__)\n",
        "CURRDIR = f\"/content/drive/MyDrive/Colab Notebooks/ML class/\"\n",
        "TRAINPATH = os.path.join(CURRDIR, \"train/\")\n",
        "VALPATH = os.path.join(CURRDIR, \"val/\")\n",
        "TESTPATH = os.path.join(CURRDIR, \"test/\")\n",
        "MODELFILEPATH = os.path.join(CURRDIR, \"save/weights.keras\") # novo formato de arquivo (hdf5 deprecated)"
      ],
      "metadata": {
        "id": "tGQp8Y5MeypF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Construção e treinamento do modelo CNN</h1>"
      ],
      "metadata": {
        "id": "7jKj_xlwhg-k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define qual a posição do canal de cores num possível array de leitura via biblioteca de Processamento de Imagens (channels_last (rows, cols, channels) // channels_first (channels, rows, cols)"
      ],
      "metadata": {
        "id": "PsQZKfPUfxq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "K.set_image_data_format('channels_last')"
      ],
      "metadata": {
        "id": "Tqdu3BA8hcCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Montagem da CNN</h3>\n",
        "\n",
        "Informações:\n",
        "\n",
        "**Ativação Relu:** se o valor 'x' que estiver na saída do neurônio for x < 0, então x = 0; senão (positivo) é o próprio valor (x = x). É uma função computacionalmente leve, entretanto não é centrada em zero. Tende a propagar valores positivos para manter neurônios relevantes ativados.\n",
        "\n",
        "**Ativação Softmax:** converte um vetor de values para uma distribuição de probabilidades. Ou seja, define um percentual de certeza de acerto para cada classe.\n",
        "\n",
        "**Otimizador Adam:** é um método de gradiente descendente estocástico baseado na estimativa de momento adaptável de primeira e segunda ordem.\n",
        "O método é realmente eficiente ao trabalhar com grandes problemas envolvendo muitos dados ou parâmetros. Requer menos memória e é eficiente.\n",
        "\n",
        "Outros ativadores podem ser vistos em: https://keras.io/api/layers/activations/\n",
        "\n",
        "Outros otimizadores podem ser vistos em: https://keras.io/api/optimizers/\n",
        "\n",
        "Mais info sobre modelos Sequential e Functional podem ser vistos em: https://www.tensorflow.org/guide/keras/sequential_model e https://www.tensorflow.org/guide/keras/functional"
      ],
      "metadata": {
        "id": "jBzpdnYhhp4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "model = Sequential()  # define que o modelo é composto de camadas sequenciais\n",
        "# Primeiras duas camadas (aguardam imagens de um canal, i.e. grayscale)\n",
        "# Se quiser analisar os 3 canais de cores, informar na construção do modelo: (w, h, 3) <==> (3, w, h)\n",
        "model.add(Reshape((1, 100, 100), input_shape=(100, 100, 1)))  # define que todas as entradas serão tratadas como imagens 100x100, 1 canal\n",
        "model.add(Conv2D(32, (5, 5), input_shape=(1, 100, 100), activation='relu', padding='same'))  # define o uso de 24 filtros 5x5, função de ativação Relu\n",
        "\n",
        "# Exemplo da camada 5x5 com regularização aplicada\n",
        "# model.add(Conv2D(32, (5, 5), input_shape=(1, 100, 100), activation='relu', padding='same', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "\n",
        "# Demais camadas\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))  # define um downsize das imagens (50% para cada dimensão)\n",
        "model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))  # define o uso de 12 filtros 5x5, função de ativação Relu\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))  # define um downsize das imagens (50% para cada dimensão)\n",
        "model.add(Flatten())  # transforma a matriz 2D em um único vetor\n",
        "model.add(Dense(64, activation='relu'))    # conecta todas as saídas do vetor a uma rede FC de 72 neurônios, ativação Relu\n",
        "model.add(Dense(3, activation='softmax'))  # conecta os 64 neurônios da camada anterior a 3 neurônios (classes possíveis de saída), ativação Softmax (define a % de certeza)\n",
        "\n",
        "# Compilando o modelo\n",
        "#model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  # categorial_crossentropy serve para várias classes de saída (se não, seria binary_crossentropy)\n",
        "\n",
        "# Adicionando mais métricas na compilação, para monitoramento com learning curves\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\", tf.keras.metrics.Precision(name=\"precision\"), tf.keras.metrics.Recall(name=\"recall\"), tf.keras.metrics.AUC(name=\"AUC\")])  # categorial_crossentropy serve para várias classes de saída (se não, seria binary_crossentropy)\n",
        "\n",
        "# Incluindo uma métrica customizada\n",
        "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"get_F1_score\", \"accuracy\", tf.keras.metrics.Precision(name=\"precision\"), tf.keras.metrics.Recall(name=\"recall\"), tf.keras.metrics.AUC(name=\"AUC\")])  # categorial_crossentropy serve para várias classes de saída (se não, seria binary_crossentropy)\n"
      ],
      "metadata": {
        "id": "bTqjSD1yhmOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sumarização do modelo CNN gerado"
      ],
      "metadata": {
        "id": "7KIoh6oMlfQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "xA96U2wkljEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparando o dataset de treinamento. Nesse caso, estamos normalizando as imagens e definindo uma configuração de aumentação de dados (no caso, além da imagem original, uma versão com flip horizontal pode ser considerada na rodada de treinamento).\n",
        "\n",
        "ADENDO: Fiz a inclusão de um dataset para validação usando model.evaluation, e aumentei proporcionalmente os datasets.\n",
        "\n",
        "Divisão do dataset organizada em diretórios de 60/20/20. São 30 imagens por classe para treinamento, e 10 imagens por classe para validação. Mais adiante, para teste, são 10 por classe."
      ],
      "metadata": {
        "id": "iaDyBixUljvY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "X_train = train_datagen.flow_from_directory(\n",
        "    TRAINPATH,\n",
        "    target_size=(100, 100),\n",
        "    batch_size=10,\n",
        "    color_mode='grayscale')  # se colorido, 'rgb' (lembre que o modelo precisa estar preparado também para 3 canais)\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "X_val = val_datagen.flow_from_directory(\n",
        "    VALPATH,\n",
        "    target_size=(100, 100),\n",
        "    color_mode='grayscale')  # se colorido, 'rgb' (lembre que o modelo precisa estar preparado também para 3 canais)\n",
        "\n",
        "Y_train = X_train.classes\n",
        "Y_val = X_val.classes\n",
        "\n",
        "#X_train.class_indices\n",
        "#Y_train.shape,Y_val.shape"
      ],
      "metadata": {
        "id": "P91sNvdjnDxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Curvas de Aprendizado**\n",
        "Criação de uma função para desenhar os gráficos.\n",
        "Importante: só podemos plotar gráficos de métricas que estamos monitorando no modelo em compilação. Verificar definição de model.compile(...)."
      ],
      "metadata": {
        "id": "e9SjMWcDAGih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Métrica F1-Score customizada para monitoramento de modelo em compilação\n",
        "# Por padrão, ela não está disponível por TF/keras. Porém, podemos criar métricas\n",
        "# personalizadas e adicionar ao processo.\n",
        "def get_F1_score(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val\n",
        "\n",
        "# Geração das curvas\n",
        "def plotar_historico(history):\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['Treinamento', 'Validação'], loc='upper left'),\n",
        "    plt.show()\n",
        "    #Caso queira imprimir o gráfico, ao invés de mostrar, use:\n",
        "    #plt.savefig(os.path.join(CURRDIR, \"save/model_loss.png\"))\n",
        "    print('')\n",
        "\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['Treinamento', 'Validação'], loc='upper left'),\n",
        "    plt.show()\n",
        "    print('')\n",
        "\n",
        "    plt.plot(history.history['precision'])\n",
        "    plt.plot(history.history['val_precision'])\n",
        "    plt.title('model precision')\n",
        "    plt.ylabel('precision')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['Treinamento', 'Validação'], loc='upper left')\n",
        "    plt.show()\n",
        "    print('')\n",
        "\n",
        "    plt.plot(history.history['AUC'])\n",
        "    plt.plot(history.history['val_AUC'])\n",
        "    plt.title('model AUC')\n",
        "    plt.ylabel('AUC')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['Treinamento', 'Validação'], loc='upper left')\n",
        "    plt.show()\n",
        "    print('')\n",
        "\n",
        "    plt.plot(history.history['recall'])\n",
        "    plt.plot(history.history['val_recall'])\n",
        "    plt.title('model recall')\n",
        "    plt.ylabel('recall')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['Treinamento', 'Validação'], loc='upper left')\n",
        "    plt.show()\n",
        "    print('')\n",
        "'''\n",
        "    plt.plot(history.history['get_F1_score'])\n",
        "    plt.plot(history.history['val_get_F1_score'])\n",
        "    plt.title('Model F1 score')\n",
        "    plt.ylabel('F1 score')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Treinamento', 'Validação'], loc='upper left')\n",
        "    plt.show()\n",
        "    print('')\n",
        "'''"
      ],
      "metadata": {
        "id": "3eqpesHeADbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definindo que queremos salvar o modelo com seus pesos (a ideia é depois usar somente o arquivo final com o modelo inteligente)\n",
        "\n",
        "ADENDO: inclui uma callback early_stop para parar o treinamento antes de tender a um overfitting."
      ],
      "metadata": {
        "id": "vIJ6kDDpnigm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='loss',\n",
        "    mode='min',\n",
        "    verbose=1,\n",
        "    patience=5)\n",
        "#Early stopping to avoid overfitting of model\n",
        "\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=MODELFILEPATH,\n",
        "    monitor='loss',\n",
        "    verbose=1,\n",
        "    mode='max')\n",
        "#Save the Keras model or model weights at some frequency\n",
        "\n",
        "callbacks_list = [checkpoint, early_stop]"
      ],
      "metadata": {
        "id": "Bh7UWIHqn2Q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinando o modelo para gerar, após as épocas, o modelo definitivo.\n",
        "ADENDO: aumentei o número de épocas (20 para 50) e o batch_size (5 para 10)."
      ],
      "metadata": {
        "id": "BAYJ8wE4n6FM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train,\n",
        "    steps_per_epoch=len(X_train),\n",
        "    validation_data= X_val,\n",
        "    validation_steps=len(X_val),\n",
        "    epochs=50,\n",
        "    batch_size=10,\n",
        "    verbose=1,\n",
        "    callbacks=callbacks_list)"
      ],
      "metadata": {
        "id": "gjeWe85vn3VR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ADENDO: como estou usando um dataset de validação, faço um evaluate nele.\n",
        "Importante que as métricas precisam ser parecidas com o treinamento. Quanto mais próximo, melhor o ajuste."
      ],
      "metadata": {
        "id": "GnItnfjYPHCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.evaluate(X_val, batch_size=10, verbose=1)\n",
        "dict(zip(model.metrics_names, prediction))"
      ],
      "metadata": {
        "id": "gdEmgIaeAdP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ** Desenhando as curvas de aprendizado, e salvando o histórico de compilação **"
      ],
      "metadata": {
        "id": "nS57eRPCASDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plotar historico\n",
        "plotar_historico(history)\n",
        "\n",
        "# salvar historico\n",
        "hist_df = pd.DataFrame(history.history)\n",
        "hist_df.to_csv(os.path.join(CURRDIR, \"save/history.csv\"))"
      ],
      "metadata": {
        "id": "9E9wxtCqAT3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Usando o modelo e testando sua predição com novas entradas</h1>"
      ],
      "metadata": {
        "id": "Eqfk4ndToFjz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carregando o arquivo que contém o modelo treinado (apenas um exemplo de como carregar um modelo já criado - não usado nesse exemplo)."
      ],
      "metadata": {
        "id": "IZ-w1WQ1oIaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = load_model(MODELFILEPATH)\n",
        "# model = load_model(MODELFILEPATH, custom_objects={'get_F1_score':get_F1_score}) # <<== esta linha aqui se salvou alguma métrica customizada"
      ],
      "metadata": {
        "id": "l8CSsZ_zoMLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lendo uma nova imagem e preparando ela para verificar a qual classe pertence (no caso, círculo, quadrado ou triângulo)\n",
        "\n",
        "ADENDO: para o exercício, estou fazendo uma varredura no diretório usando sorted (para buscar em ordem alfabética)\n",
        "\n",
        "Importante que a entrada precisa ser convertida para a mesma configuração que o modelo foi treinado (nesse caso, 100x100, grayscale)\n",
        "\n",
        "-----\n",
        "\n",
        "Faz a predição da entrada, e pega somente a classe que tem o maior percentual de certeza\n",
        "\n",
        "ADENDO: faço também uma rápida predição aqui, arquivo por arquivo.\n",
        "\n",
        "Saída final de categorização"
      ],
      "metadata": {
        "id": "5WnK5f4FoP-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#img = image.load_img(FILETESTPATH, target_size=(100, 100), color_mode='grayscale')\n",
        "#y = image.img_to_array(img)\n",
        "#y = np.expand_dims(y, axis=0)\n",
        "\n",
        "# load all images into a list\n",
        "images = []\n",
        "for img in sorted(os.listdir(TESTPATH)):\n",
        "  print(img)\n",
        "  img = os.path.join(TESTPATH, img)\n",
        "  img = image.load_img(img, target_size=(100, 100), color_mode='grayscale')  # se colorido, 'rgb'\n",
        "  img = image.img_to_array(img)\n",
        "  img = np.expand_dims(img, axis=0)\n",
        "  images.append(img)\n",
        "  predict = model.predict(img)\n",
        "  classes = np.argmax(predict, axis=1)\n",
        "  if(classes[0]==0): print(\"CÍRCULO!\")\n",
        "  elif(classes[0]==1): print(\"QUADRADO!\")\n",
        "  else: print(\"TRIÂNGULO!\")\n",
        "  print(\"----------\")"
      ],
      "metadata": {
        "id": "er5z2dkioN_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ADENDO: Aqui estou lendo o banco de imagens. Como as imagens já estão em tons de cinza, deixei comentado a divisão.\n",
        "\n",
        "Carrega para uma pilha, e faz a predição de todas de uma só vez!"
      ],
      "metadata": {
        "id": "2v0Q3ULkokGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# stack up images list to pass for prediction\n",
        "#images = images/255\n",
        "images = np.vstack(images)\n",
        "result = model.predict(images)"
      ],
      "metadata": {
        "id": "jYcXLu0EogO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ADENDO: Cálculo das métricas aqui. Um pequeno ajuste para Roc AUC Score quando usamos 3 ou mais classes. Deixei comentado o padrão para casos binários (2 classes)."
      ],
      "metadata": {
        "id": "yhz1Xa1EoySD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score,recall_score,f1_score,accuracy_score\n",
        "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "Y_true = np.array([1,1,1,2,0,2,2,1,1,0,0,0,0,0,1,2,0,0,0,2,1,1,2,1,2,2,1,2,2,0]) # Como está no diretório cada img (Segue a ordem alfabética)\n",
        "Y_pred = np.argmax(result, axis=1) # Pega só o maior valor, torna a matriz 1D\n",
        "\n",
        "cm = confusion_matrix(Y_true, Y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Círculo\", \"Quadrado\", \"Triângulo\"])\n",
        "disp.plot(cmap='GnBu')\n",
        "\n",
        "plt.show()\n",
        "# Por padrão, average = binary (2 classes). Aqui são 3, optei em usar \"micro\".\n",
        "print('Precision: %.3f' % precision_score(Y_true, Y_pred, average='micro'))\n",
        "print('Recall: %.3f' % recall_score(Y_true, Y_pred, average='micro'))\n",
        "print('F1: %.3f' % f1_score(Y_true, Y_pred, average='micro'))\n",
        "print('Accuracy: %.3f' % accuracy_score(Y_true, Y_pred))\n",
        "\n",
        "# Para duas classes:\n",
        "# print('Roc AUC Score: %.3f' % roc_auc_score(Y_true, Y_pred, average='macro'))\n",
        "# fpr, tpr, thresholds = roc_curve(Y_true, Y_pred)\n",
        "\n",
        "# plt.xlabel('Taxa de Falsos Positivos')\n",
        "# plt.ylabel('Taxa de Verdadeiros Positivos')\n",
        "# plt.title('Curva ROC')\n",
        "# plt.plot(fpr, tpr)\n",
        "\n",
        "class_names = ['Círculo', 'Quadrado', 'Triângulo']\n",
        "\n",
        "# Binarize ytest with shape (n_samples, n_classes)\n",
        "ytrues = label_binarize(Y_true, classes=[0, 1, 2])\n",
        "n_classes = ytrues.shape[1]\n",
        "\n",
        "# Binarize ypreds with shape (n_samples, n_classes)\n",
        "ypreds = label_binarize(Y_pred, classes=[0, 1, 2])\n",
        "\n",
        "print('Roc AUC Score (OVR): %.3f' % roc_auc_score(ytrues, ypreds, multi_class='ovr'))\n",
        "\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "  fpr[i], tpr[i], _ = roc_curve(ytrues[:, i], ypreds[:, i])\n",
        "  roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "colors = cycle(['blue', 'red', 'green'])\n",
        "for i, color in zip(range(n_classes), colors):\n",
        "  plt.plot(fpr[i], tpr[i], color=color, lw=1.5,\n",
        "            label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "            ''.format(class_names[i], roc_auc[i]))\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=1.5)\n",
        "plt.xlim([-0.05, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic for multi-class data')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s7nPYsvOo1Cg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "\n",
        "# Tratamento para Curva PR Multiclasse\n",
        "print('')\n",
        "precision = dict()\n",
        "recall = dict()\n",
        "average_precision = dict()\n",
        "for i in range(n_classes):\n",
        "    precision[i], recall[i], _ = precision_recall_curve(ytrues[:, i], ypreds[:, i])\n",
        "    average_precision[i] = average_precision_score(ytrues[:, i], ypreds[:, i])\n",
        "\n",
        "# A \"micro-average\": quantifying score on all classes jointly\n",
        "precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(ytrues.ravel(), ypreds.ravel())\n",
        "average_precision[\"micro\"] = average_precision_score(ytrues, ypreds, average=\"micro\")\n",
        "\n",
        "colors = cycle(['blue', 'red', 'green'])\n",
        "for i, color in zip(range(n_classes), colors):\n",
        "  plt.plot(recall[i], precision[i], color=color, lw=1.5,\n",
        "            label='PR curve of class {0} (area = {1:0.2f})'\n",
        "            ''.format(class_names[i], average_precision[i]))\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=1.5)\n",
        "plt.xlim([-0.05, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Prediction')\n",
        "plt.title('Precision-Recall curve to multi-class')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "print('AP Score (Micro)...: {0:0.3f}'.format(average_precision[\"micro\"]))\n"
      ],
      "metadata": {
        "id": "hh9XqjMKJhXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fontes para Model Evaluation:\n",
        "#https://www.tensorflow.org/guide/keras/train_and_evaluate\n",
        "#https://www.analyticsvidhya.com/blog/2021/07/step-by-step-guide-for-image-classification-on-custom-datasets/\n",
        "#https://machinelearningmastery.com/how-to-calculate-precision-recall-f1-and-more-for-deep-learning-models/\n",
        "#https://www.projectpro.io/recipes/evaluate-keras-model#mcetoc_1g2a1msp0d\n",
        "#https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model\n",
        "#https://gist.github.com/ritiek/5fa903f97eb6487794077cf3a10f4d3e\n",
        "#https://androidkt.com/how-to-predict-images-using-trained-keras-model/\n",
        "#https://stackoverflow.com/questions/33547965/computing-auc-and-roc-curve-from-multi-class-data-in-scikit-learn-sklearn\n",
        "#https://stackoverflow.com/questions/63303682/sklearn-multiclass-roc-auc-score\n",
        "#https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
        "\n",
        "#Fontes para Bias/Variance/Learning Curves:\n",
        "#https://www.tensorflow.org/tutorials/keras/overfit_and_underfit?hl=pt-br\n",
        "#https://www.geeksforgeeks.org/bias-vs-variance-in-machine-learning/\n",
        "#https://rasbt.github.io/mlxtend/user_guide/evaluate/bias_variance_decomp/\n",
        "#https://www.kaggle.com/code/azminetoushikwasi/mastering-bias-variance-tradeoff\n",
        "#https://www.kaggle.com/code/nicolaugoncalves/curvas-de-aprendizado\n",
        "#https://bixtecnologia.com.br/como-entender-vies-e-variancia-em-modelos-preditivos/\n",
        "#https://stackabuse.com/the-bias-variance-trade-off-in-machine-learning/\n",
        "#https://medium.com/data-hackers/o-que-é-bias-variance-tradeoff-a5bc19866e4b\n",
        "#https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/"
      ],
      "metadata": {
        "id": "RqPn5FkfFr0A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}