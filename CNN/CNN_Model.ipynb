{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "import numpy as np\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import load_img, img_to_array\n",
    "# from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Essas linhas fazem a montagem do Meu Drive via código: ###\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# CURRDIR = os.path.dirname(__file__)\n",
    "CURRDIR = f\"CNN_dataset/\"\n",
    "TRAINPATH = os.path.join(CURRDIR, \"train/\")\n",
    "FILETESTPATH = os.path.join(CURRDIR, \"test/2.png\")\n",
    "MODELFILEPATH = os.path.join(CURRDIR, \"weights.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input e Maxpool não tem hiperparâmetros   -    Função MAXPOOL é reduzir o tamanho da imagem     -    Função SOFTMAX é categorizar nas classes do problema\n",
    "A cada camada CONV estamos aplicando zero padding   -   Conv +Pool considera-se uma camada apenas   -  Flatten transfere de uma dimensão p/ outra (nesse caso 2D [matriz] para 1D [vetor])\n",
    "Fully-Connected (FC) é chamada assim pq tem 400 neurônios interconectados c/ todos os 120 da camada seguinte (Tradicional Perceptron Model)\n",
    "Hiperparâmetros p/ camadas convolucionais = (w filtro x h filtro x filtros camada anterior + 1) * filtros camada atual = (5x5x3+1)*6 = 456 (esse 1 é bias do filtro)\n",
    "Hiperparâmetros p/ camadas FC = (current layer neurons c * previous layer neurons p)+(1*c).  (120 * 400) + (1*120) = 48120\n",
    "Nota-se que o número nW x nH diminui a medida que aprofundamos a rede... Porém, o número de filtros aumenta nF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()  # define que o modelo é composto de camadas sequências\n",
    "# Adicionando camadas\n",
    "model.add(Reshape((3,100,100), input_shape=(100, 100, 3)))  # define que todas as entradas serão tratadas como imagens 100x100, 1 canal\n",
    "model.add(Conv2D(16, (3, 4), input_shape=(3, 100, 100), activation='relu', padding='same'))  # define o uso de 20 filtros 5x5, função de ativação Relu\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))  # define um downsize das imagens (50% para cada dimensão)\n",
    "model.add(Conv2D(8, (3, 3), activation='relu', padding='same'))  # define o uso de 10 filtros 3x3, função de ativação Relu\n",
    "model.add(Flatten())  # transforma a matriz 2D em um único vetor\n",
    "model.add(Dense(32, activation='relu'))  # conecta todas as saídas do vetor a uma rede FC de 64 neurônios, ativação Relu\n",
    "model.add(Dense(2, activation='softmax'))  # conecta os 64 neurônios da camada anterior a 2 neurônios (classes possíveis de saída), ativação Softmax (define a % de certeza)\n",
    "\n",
    "# Compilando o modelo\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  # categorial_crossentropy serve para várias classes de saída (se não, seria binary_crossentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape_2 (Reshape)         (None, 3, 100, 100)       0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 3, 100, 16)        19216     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 2, 50, 16)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 2, 50, 8)          1160      \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 800)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                25632     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 46074 (179.98 KB)\n",
      "Trainable params: 46074 (179.98 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "X_train = train_datagen.flow_from_directory(\n",
    "    TRAINPATH,\n",
    "    target_size=(100, 100),\n",
    "    batch_size=5,\n",
    "    color_mode='rgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    MODELFILEPATH,\n",
    "    monitor='val_accuracy',\n",
    "    verbose=1,\n",
    "    mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - ETA: 0s - loss: 0.6477 - accuracy: 0.6200\n",
      "Epoch 1: saving model to CNN_dataset\\weights.hdf5\n",
      "10/10 [==============================] - 2s 54ms/step - loss: 0.6477 - accuracy: 0.6200\n",
      "Epoch 2/20\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.7578 - accuracy: 0.4500\n",
      "Epoch 2: saving model to CNN_dataset\\weights.hdf5\n",
      "10/10 [==============================] - 0s 48ms/step - loss: 0.7253 - accuracy: 0.4800\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5232 - accuracy: 0.7200\n",
      "Epoch 3: saving model to CNN_dataset\\weights.hdf5\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.5232 - accuracy: 0.7200\n",
      "Epoch 4/20\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.4505 - accuracy: 0.8000\n",
      "Epoch 4: saving model to CNN_dataset\\weights.hdf5\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 0.4407 - accuracy: 0.8000\n",
      "Epoch 5/20\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3132 - accuracy: 0.8889\n",
      "Epoch 5: saving model to CNN_dataset\\weights.hdf5\n",
      "10/10 [==============================] - 1s 33ms/step - loss: 0.3268 - accuracy: 0.8600\n",
      "Epoch 6/20\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.3193 - accuracy: 0.8444\n",
      "Epoch 6: saving model to CNN_dataset\\weights.hdf5\n",
      "10/10 [==============================] - 1s 58ms/step - loss: 0.3024 - accuracy: 0.8600\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2680 - accuracy: 0.9000\n",
      "Epoch 7: saving model to CNN_dataset\\weights.hdf5\n",
      "10/10 [==============================] - 1s 59ms/step - loss: 0.2680 - accuracy: 0.9000\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2187 - accuracy: 0.9600\n",
      "Epoch 8: saving model to CNN_dataset\\weights.hdf5\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.2187 - accuracy: 0.9600\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1411 - accuracy: 0.9400\n",
      "Epoch 9: saving model to CNN_dataset\\weights.hdf5\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.1411 - accuracy: 0.9400\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.1113 - accuracy: 1.0000\n",
      "Epoch 10: saving model to CNN_dataset\\weights.hdf5\n",
      "10/10 [==============================] - 1s 51ms/step - loss: 0.1113 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0768 - accuracy: 1.0000\n",
      "Epoch 11: saving model to CNN_dataset\\weights.hdf5\n",
      "10/10 [==============================] - 1s 52ms/step - loss: 0.0762 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0797 - accuracy: 1.0000\n",
      "Epoch 12: saving model to CNN_dataset\\weights.hdf5\n",
      "10/10 [==============================] - 1s 58ms/step - loss: 0.0797 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0646 - accuracy: 1.0000\n",
      "Epoch 13: saving model to CNN_dataset\\weights.hdf5\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.0660 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0441 - accuracy: 1.0000\n",
      "Epoch 14: saving model to CNN_dataset\\weights.hdf5\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 0.0441 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0435 - accuracy: 1.0000\n",
      "Epoch 15: saving model to CNN_dataset\\weights.hdf5\n",
      "10/10 [==============================] - 1s 50ms/step - loss: 0.0435 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0335 - accuracy: 1.0000\n",
      "Epoch 16: saving model to CNN_dataset\\weights.hdf5\n",
      "10/10 [==============================] - 1s 49ms/step - loss: 0.0335 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0295 - accuracy: 1.0000\n",
      "Epoch 17: saving model to CNN_dataset\\weights.hdf5\n",
      "10/10 [==============================] - 1s 35ms/step - loss: 0.0311 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0227 - accuracy: 1.0000\n",
      "Epoch 18: saving model to CNN_dataset\\weights.hdf5\n",
      "10/10 [==============================] - 1s 62ms/step - loss: 0.0227 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 1.0000\n",
      "Epoch 19: saving model to CNN_dataset\\weights.hdf5\n",
      "10/10 [==============================] - 1s 33ms/step - loss: 0.0208 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.0129 - accuracy: 1.0000\n",
      "Epoch 20: saving model to CNN_dataset\\weights.hdf5\n",
      "10/10 [==============================] - 1s 53ms/step - loss: 0.0117 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x239f1ed4a60>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    steps_per_epoch=len(X_train),\n",
    "    epochs=20,\n",
    "    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(MODELFILEPATH)\n",
    "\n",
    "# model = load_model(MODELFILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img(FILETESTPATH, target_size=(100, 100), color_mode='rgb')\n",
    "y = img_to_array(img)\n",
    "y = np.expand_dims(y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 131ms/step\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict(y)\n",
    "classes = np.argmax(predict, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QUADRADO!\n"
     ]
    }
   ],
   "source": [
    "if(classes[0]==0): print(\"\\nQUADRADO!\")\n",
    "else: print(\"\\nTRIÂNGULO!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step\n",
      "1.png é um QUADRADO!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n",
      "2.png é um QUADRADO!\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "3.png é um TRIÂNGULO!\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "4.png é um TRIÂNGULO!\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "5.png é um TRIÂNGULO!\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "6.png é um QUADRADO!\n"
     ]
    }
   ],
   "source": [
    "directory = f\"CNN_dataset/test\"\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    img = load_img(f, target_size=(100, 100), color_mode='rgb')\n",
    "    y = img_to_array(img)\n",
    "    y = np.expand_dims(y, axis=0)\n",
    "    predict = model.predict(y)\n",
    "    classes = np.argmax(predict, axis=1)\n",
    "    if(classes[0]==0): print(filename + \" é um QUADRADO!\")\n",
    "    else: print(filename + \" é um TRIÂNGULO!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
